{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gcve0XQAIuAO"
      ],
      "authorship_tag": "ABX9TyMzqAd83OemSqAd4ShyeLMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spike-h/mdai/blob/main/MD.ai_to_SR_and_SEG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mdai pydicom"
      ],
      "metadata": {
        "id": "fHUD35trL4zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SR_SEG_Export Documentation & Source Code\n",
        "\n",
        "This class is used to export you're MD.ai annotations into DICOM SR or SEG format.\n",
        "\n",
        "______\n",
        "### SR Exports\n",
        "If your output format is SR, all annotations will be converted, capturing the label's and their parent's name in SR format (The specific Code Value of each annotation will be arbitrary). An SR file will be created for each annotator in each annotated **study**. The SR's DICOM data will be consistent with the study it references. The study and annotation information comes from the inputted \"Annotation Json\" and \"Metadata Json\" (These jsons have to be referencing the same dataset(s) for it to work).\n",
        "\n",
        "The labels will be ordered from exam level to series to image. Each image level label will have a \"Referenced Image\" section preceding the label to indicate it's source. Series labels will have \"Series UID: xxx\" under them for better referencing as well.\n",
        "______\n",
        "### Segmentation Exports\n",
        "If your output format is SEG, only local annotations will be exported. This export process converts the annotation data into a binary mask, and creates the relevant segmentation DICOM data to export a DICOM Segmentation file. A Segmentation file will be created for each annotator in each annotated **series**. Additionally, if `combine_label_groups` is `False`, a different file will be created for each label group. The file's DICOM headers will be consistent with the original DICOM's. The study and annotation information comes from the inputted \"Annotation Json\" and \"Metadata Json\" (These jsons have to be referencing the same dataset(s) for it to work).\n",
        "\n",
        "The segmentation frames are grouped together by their labels and within those groups, they are ordered by their source's frame number.\n",
        "______\n",
        "\n",
        "  Inputs:\n",
        "\n",
        "    `output_format` - determines if the output should be in DICOM SR/SEG\n",
        "                      (accepted inputs are \"SR\" or \"SEG\")\n",
        "    `annotation_json` & `metadata_json` - are the exported annotation and metadata json paths from the md.ai project\n",
        "                                          MAKE SURE THE DATASETS MATCH UP\n",
        "    `combine_label_groups` - If `True` then each SEG file includes the annotations from every label group for that series\n",
        "                             If `False` then a different SEG file will be created for each different label group annotation\n",
        "                            (only applies to SEG output. Will be ignored for SR)\n",
        "    `output_dir` - Specifies where the files should be downloaded\n",
        "                   If None then files will be placed in a \"SR(or SEG)_OUTPUT\" folder in your cwd.\n",
        "Outputs:\n",
        "\n",
        "`\n",
        "  There will be a folder in your cwd, specified by the output_dir parameter, containing your SR/SEG exports.\n",
        "`"
      ],
      "metadata": {
        "id": "lu7VtBvJOV5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage:"
      ],
      "metadata": {
        "id": "hbSiobs9koED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generated from Clarence's GPT documentation project\n",
        "\n",
        "import mdai\n",
        "from glob import glob\n",
        "\n",
        "# Define your personal token and project id\n",
        "personal_token = '8b80c4ca0f05'\n",
        "project_id = 'LFdpnJGv'\n",
        "\n",
        "# Create an mdai client\n",
        "mdai_client = mdai.Client(domain='public.md.ai', access_token=personal_token)\n",
        "\n",
        "# Download the annotation data only (all label groups)\n",
        "p = mdai_client.project(project_id, path='.',  annotations_only=True)\n",
        "\n",
        "# Download only the DICOM metadata\n",
        "p = mdai_client.download_dicom_metadata(project_id, format ='json', path='.')\n",
        "\n",
        "# Use glob to find the downloaded json files (or get them manually)\n",
        "annotation_file = glob('*annotations*.json')[0]\n",
        "metadata_file = glob('*dicom_metadata*.json')[0]\n",
        "\n",
        "# Use the SR_SEG_Export class to export the annotations to DICOM SR/SEG format\n",
        "\n",
        "# Should replace to mdai.SR_SEG_Export once integrated with library\n",
        "exporter = SR_SEG_Export(\n",
        "    output_format = 'SEG',\n",
        "    annotation_json = annotation_file,\n",
        "    metadata_json = metadata_file,\n",
        "    output_dir = 'out_folder'\n",
        ")"
      ],
      "metadata": {
        "id": "FQmj_3-Lksyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source Code To Convert MD.ai annotations to SR/SEG"
      ],
      "metadata": {
        "id": "gcve0XQAIuAO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL5JW-Y-LzNY"
      },
      "outputs": [],
      "source": [
        "import mdai\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "import requests\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import pydicom\n",
        "from pydicom.filereader import dcmread\n",
        "from pydicom.dataset import Dataset, FileMetaDataset\n",
        "from pydicom.pixel_data_handlers.numpy_handler import pack_bits\n",
        "from pydicom.sequence import Sequence\n",
        "\n",
        "# Imports and Parse Some of the DICOM Standard Files\n",
        "# -----------------------------------------------\n",
        "class SR_SEG_Export:\n",
        "  '''\n",
        "  Used to convert md.ai annotations to DICOM SR/SEG format for easier data processing.\n",
        "\n",
        "  Inputs:\n",
        "    `output_format` - determines if the output should be in DICOM SR/SEG (accepted inputs are \"SR\" or \"SEG\")\n",
        "    `annotation_json` & `metadata_json` - are the exported annotation and metadata json paths from the md.ai project\n",
        "                                              MAKE SURE THE DATASETS MATCH UP\n",
        "    `combine_label_groups` - If `True` then each SEG file includes the annotations from every label group for that series\n",
        "                             If `False` then a different SEG file will be created for each different label group annotation\n",
        "                            (only applies to SEG output. Will be ignored for SR)\n",
        "    `output_dir` - Specifies where the files should be downloaded\n",
        "                   If None then files will be placed in a \"SR(or SEG)_OUTPUT\" folder in your cwd.\n",
        "\n",
        "  Outputs:\n",
        "    There will be a folder in your cwd, specified by the `output_dir` parameter, containing your SR/SEG exports.\n",
        "\n",
        "  Created by Dyllan Hofflich. (8/4/23)\n",
        "  '''\n",
        "  def __init__(self, output_format, annotation_json, metadata_json, combine_label_groups=True, output_dir=None):\n",
        "    self.Annotation_Json = annotation_json\n",
        "    self.Metadata_Json = metadata_json\n",
        "    self.output_format = output_format\n",
        "    self.combine = combine_label_groups\n",
        "    self.output_dir = output_dir\n",
        "\n",
        "    if output_format != 'SR' and output_format != 'SEG':\n",
        "      raise Exception('Invalid output format. Must be either \"SR\" or \"SEG\"')\n",
        "\n",
        "    self.dicom_standards_setups()\n",
        "    self.dicom_tags_setup()\n",
        "    if output_format == 'SR':\n",
        "      self.create_sr_exports()\n",
        "    else:\n",
        "      self.create_seg_exports()\n",
        "\n",
        "  def dicom_standards_setups(self):\n",
        "    \"\"\"\n",
        "    Searches the DICOM standard to gather which dicom tags are relevant to SR/Segmentation and which tags should be copied over from the original images.\n",
        "    Gathers the DICOM standard data from https://github.com/innolitics/dicom-standard which is used in the Standard DICOM Browser website.\n",
        "    \"\"\"\n",
        "\n",
        "    ctm_json = requests.get('https://raw.githubusercontent.com/innolitics/dicom-standard/master/standard/ciod_to_modules.json').text\n",
        "    mta_json = requests.get('https://raw.githubusercontent.com/innolitics/dicom-standard/master/standard/module_to_attributes.json').text\n",
        "    attributes_json = requests.get('https://raw.githubusercontent.com/innolitics/dicom-standard/master/standard/attributes.json').text\n",
        "    # ciod_to_modules_dataframe\n",
        "    ctm_df = pd.read_json(ctm_json)\n",
        "    # module_to_attributes_dataframe\n",
        "    mta_df = pd.read_json(mta_json)\n",
        "    # attributes_dataframe\n",
        "    attributes_df = pd.read_json(attributes_json)\n",
        "\n",
        "    # Select basic-text-sr/SEG modules\n",
        "    if self.output_format == 'SR':\n",
        "      SR_modules_df = ctm_df[ctm_df['ciodId'] == 'basic-text-sr']\n",
        "    else:\n",
        "      SR_modules_df = ctm_df[ctm_df['ciodId'] == 'segmentation']\n",
        "    # Select all basic-text-sr/SEG attributes\n",
        "    SR_attributes_df = mta_df[mta_df['moduleId'].isin(SR_modules_df['moduleId'])]\n",
        "\n",
        "    attribute_to_keyword_map = dict(zip(attributes_df['tag'], attributes_df['keyword']))\n",
        "    self.keyword_to_VR_map = dict(zip(attributes_df['keyword'], attributes_df['valueRepresentation']))\n",
        "    attribute_to_type_map = dict(zip(SR_attributes_df['tag'], SR_attributes_df['type']))\n",
        "\n",
        "    self.keyword_to_type_map = {}\n",
        "    for attribute in attribute_to_type_map:\n",
        "      self.keyword_to_type_map[attribute_to_keyword_map[attribute]] = attribute_to_type_map[attribute]\n",
        "\n",
        "    # Create dicom heirarchy for SR/SEG document (modeled after the Standard DICOM Browser)\n",
        "    # ---------------------------------------------------\n",
        "    SR_attributes_df.sort_values('path')\n",
        "    self.dicom_tag_heirarchy = {}\n",
        "    for _, row in SR_attributes_df.iterrows():\n",
        "      if row['path'].count(':') == 1:\n",
        "        self.dicom_tag_heirarchy[attribute_to_keyword_map[row['tag']]] = {}\n",
        "      else:\n",
        "        paths = row['path'].split(':')\n",
        "        #convert all tags in path to tag format\n",
        "        parents = []\n",
        "        for parent in paths[1:-1]:\n",
        "          parent = f'({parent[:4]},{parent[4:]})'.upper()\n",
        "          parent = attribute_to_keyword_map[parent]\n",
        "          parents.append(parent)\n",
        "\n",
        "        child = paths[-1]\n",
        "        child = f'({child[:4]},{child[4:]})'.upper()\n",
        "        child = attribute_to_keyword_map[child]\n",
        "\n",
        "        #get to last tag sequence\n",
        "        current_sequence = self.dicom_tag_heirarchy[parents[0]]\n",
        "        for parent in parents[1:]:\n",
        "          current_sequence = current_sequence[parent]\n",
        "        current_sequence[child] = {}\n",
        "\n",
        "    # Dictionary of VR and their corresponding types\n",
        "    self.typos ={\n",
        "        'AE': str,\n",
        "        'AS': str,\n",
        "        'AT': pydicom.tag.BaseTag,\n",
        "        'CS': str,\n",
        "        'DA': str,\n",
        "        'DS': pydicom.valuerep.DSfloat,\n",
        "        'DT': str,\n",
        "        'FL': float,\n",
        "        'FD': float,\n",
        "        'IS': pydicom.valuerep.IS,\n",
        "        'LO': str,\n",
        "        'LT': str,\n",
        "        'OB': bytes,\n",
        "        'OB or OW': bytes,\n",
        "        'OD': bytes,\n",
        "        'OF': bytes,\n",
        "        'OL': bytes,\n",
        "        'OV': bytes,\n",
        "        'OW': bytes,\n",
        "        'PN': pydicom.valuerep.PersonName,\n",
        "        'SH': str,\n",
        "        'SL': int,\n",
        "        'SQ': pydicom.sequence.Sequence,\n",
        "        'SS': int,\n",
        "        'ST': str,\n",
        "        'SV': int,\n",
        "        'TM': str,\n",
        "        'UC': str,\n",
        "        'UI': pydicom.uid.UID,\n",
        "        'UL': int,\n",
        "        'UN': bytes,\n",
        "        'UR': str,\n",
        "        'US': int,\n",
        "        'US or SS': int,\n",
        "        'UT': str,\n",
        "        'UV': int,\n",
        "    }\n",
        "\n",
        "  def dicom_tags_setup(self):\n",
        "    \"\"\"\n",
        "    Organizes the dicom tags and study, series, and image level information into a more parsable structure.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read Imported JSONs\n",
        "    results = mdai.common_utils.json_to_dataframe(os.getcwd() + '/' + self.Annotation_Json)\n",
        "    self.metadata = pd.read_json(os.getcwd() + '/' + self.Metadata_Json)\n",
        "\n",
        "    # Annotations dataframe\n",
        "    self.annots_df = results['annotations']\n",
        "    labels = results['labels']\n",
        "    self.label_name_map = dict(zip(labels.labelId, labels.labelName))\n",
        "    self.label_scope_map = dict(zip(labels.labelId, labels.scope))\n",
        "\n",
        "    # Images DICOM Tags dataframe\n",
        "    tags = []\n",
        "    for dataset in self.metadata['datasets']:\n",
        "      tags.extend(dataset['dicomMetadata'])\n",
        "\n",
        "    # Create organization of study, series, instance UID & dicom tags\n",
        "    # ----------------------------------------------------------\n",
        "    self.studies = self.annots_df.StudyInstanceUID.unique()\n",
        "    self.tags_df = pd.DataFrame.from_dict(tags) # dataframe of study, series, instance UID & dicom tags\n",
        "    self.dicom_hierarchy = {}\n",
        "    for tag in tags:\n",
        "      study_uid = tag['StudyInstanceUID']\n",
        "      series_uid = tag['SeriesInstanceUID']\n",
        "      sop_uid = tag['SOPInstanceUID']\n",
        "\n",
        "      # Check if already seen study_uid yet (avoids key error)\n",
        "      if study_uid not in self.dicom_hierarchy: # Using study_uid bc rn it's exam level\n",
        "        self.dicom_hierarchy[study_uid] = []\n",
        "\n",
        "      # Dicom_heirarchy is a dictionary with study_uid as keys and a list as value\n",
        "      # each list contains a dictionary with the series_uid as a key and a list of sop_uids as value\n",
        "      if not any(series_uid in d for d in self.dicom_hierarchy[study_uid]):\n",
        "        self.dicom_hierarchy[study_uid].append({series_uid:[]})\n",
        "      for d in self.dicom_hierarchy[study_uid]: #loops through item in dicom_heriarchy list (just the series_uid dict)\n",
        "        if series_uid in d:\n",
        "          d[series_uid].append(sop_uid)\n",
        "\n",
        "  # Helper functions to place DICOM tags into SR document Template\n",
        "  # ---------------------------------------------------\n",
        "  '''\n",
        "  > Iterates through a given sequence of tags from the standard DICOM heirarchy\n",
        "  > Checks if the tag exists in the current DICOM file's headers\n",
        "  >>  If it does then it adds the tag to the SR document dataset\n",
        "  > Recursively calls itself to add tags in sequences and\n",
        "  >>  Checks if a sequence contains all its required tags and adds them if so\n",
        "  > Returns the SR document dataset with all tags added\n",
        "  > If there were no tags added then returns False\n",
        "  '''\n",
        "  def place_tags(self, dicom_tags, curr_dataset, curr_seq, need_to_check_required=True):\n",
        "    sequences = {}\n",
        "    added = False\n",
        "    # Iterate through sequence to add tags and find sequences\n",
        "    for keyword in curr_seq:\n",
        "      if keyword in dicom_tags:\n",
        "        curr_dataset = self.add_to_dataset(curr_dataset, keyword, dicom_tags[keyword], True)\n",
        "        added = True\n",
        "      if self.keyword_to_VR_map[keyword] == 'SQ':\n",
        "        sequences[keyword] = curr_seq[keyword]\n",
        "\n",
        "    # Iterate through sequences to add tags and recursively search within sequences for tags\n",
        "    for keyword in sequences:\n",
        "      if self.output_format == 'SR' and keyword == 'ContentSequence': # Skips ContentSequence since it's meant to contain the annotations data\n",
        "          continue\n",
        "      seq = sequences[keyword]\n",
        "      new_dataset = Dataset()\n",
        "      new_dataset = self.place_tags(dicom_tags, new_dataset, seq, need_to_check_required)\n",
        "      if new_dataset:\n",
        "        if self.keyword_to_VR_map[keyword] == 'SQ':\n",
        "          new_dataset = [new_dataset] # Pydicom requires sequences to be in a list\n",
        "        if not need_to_check_required or self.check_required(new_dataset, seq):\n",
        "          added = True\n",
        "          curr_dataset = self.add_to_dataset(curr_dataset, keyword, new_dataset, True)\n",
        "\n",
        "    if added:\n",
        "      return curr_dataset\n",
        "\n",
        "    return False\n",
        "\n",
        "  # Checks if a sequence contains all its required tags\n",
        "  def check_required(self, curr_dataset, curr_seq):\n",
        "    for keyword in curr_seq:\n",
        "      tag_type = self.keyword_to_type_map[keyword]\n",
        "      if keyword not in curr_dataset and '1' == tag_type:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  # Adds tag to dataset and if the tag already exists then\n",
        "  # Replaces tag if replace=True if not then does nothing\n",
        "  def add_to_dataset(self, dataset, keyword, value, replace):\n",
        "    VR = self.keyword_to_VR_map[keyword]\n",
        "\n",
        "    # If the tag is a sequence then the value in dicom_tags will be a list containing dictionary so need to convert to sequence format\n",
        "    if type(value) == list and VR == 'SQ':\n",
        "      if type(value[0]) == dict:\n",
        "        value = self.dict_to_sequence(value)\n",
        "\n",
        "    # If the tag is a byte encoding then need to switch it to so from string\n",
        "    if self.typos[VR] == bytes and value != None:\n",
        "      value = value[2:-1].encode('UTF-8') # removes b' and '\n",
        "\n",
        "    # If the tag is an int/float encoding then need to switch it to so from string\n",
        "    if self.typos[VR] == int or self.typos[VR] == float:\n",
        "      if value != None:\n",
        "        value = self.typos[VR](value)\n",
        "\n",
        "    # check if tag already in dataset\n",
        "    if keyword in dataset:\n",
        "      if not replace:\n",
        "        return dataset\n",
        "      dataset[keyword].value = value\n",
        "      return dataset\n",
        "\n",
        "    if 'or SS' in VR and type(value) == int: # Fix bug when VR == 'US or SS' and the value is negative (it always defaults to US)\n",
        "      if value < 0:\n",
        "        VR = 'SS'\n",
        "\n",
        "    dataset.add_new(keyword, VR, value)\n",
        "    return dataset\n",
        "\n",
        "  # Creates a sequence from a list of dictionaries\n",
        "  def dict_to_sequence(self, dict_seq_list):\n",
        "    sequences = []\n",
        "    for dict_seq in dict_seq_list:\n",
        "      seq = Dataset()\n",
        "      for keyword in dict_seq:\n",
        "        if self.keyword_to_VR_map[keyword] == 'SQ':\n",
        "          inner_seq = self.dict_to_sequence(dict_seq[keyword])\n",
        "          seq = self.add_to_dataset(seq, keyword, inner_seq, True)\n",
        "        else:\n",
        "          seq = self.add_to_dataset(seq, keyword, dict_seq[keyword], True)\n",
        "      sequences.append(seq)\n",
        "    return sequences\n",
        "\n",
        "  def create_sr_exports(self):\n",
        "    # Iterate through each study and create SR document for each annotator in each study\n",
        "    # Save output to Output folder\n",
        "    # ---------------------------------------------------\n",
        "    try:\n",
        "      if self.output_dir == None:\n",
        "        out_dir = 'SR_Output'\n",
        "        os.mkdir('SR_Output')\n",
        "      else:\n",
        "        out_dir = self.output_dir\n",
        "        os.mkdir(self.output_dir)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    from io import BytesIO\n",
        "    document_file = requests.get('https://github.com/spike-h/SRDocs/raw/main/Simple%20SR%20-%20RSNA.dcm')\n",
        "    for dataset_id in self.annots_df['datasetId'].unique():\n",
        "      self.dataset_annots = self.annots_df[self.annots_df.datasetId == dataset_id]\n",
        "      for study_uid in self.studies:\n",
        "        #load file template\n",
        "        ds = dcmread(BytesIO(document_file.content))\n",
        "\n",
        "        self.dicom_tags = self.tags_df[self.tags_df.StudyInstanceUID == study_uid].dicomTags.values[0]\n",
        "        annotations = self.dataset_annots[self.dataset_annots.StudyInstanceUID == study_uid]\n",
        "\n",
        "        annotators = annotations.createdById.unique()\n",
        "        series_uid = pydicom.uid.generate_uid(prefix=None)\n",
        "        instance_uid = pydicom.uid.generate_uid(prefix=None)\n",
        "        date = datetime.now().strftime('%Y%m%d')\n",
        "        time = datetime.now().strftime('%H%M%S')\n",
        "\n",
        "        # Place all the tags from the dicom into the SR document\n",
        "        ds = self.place_tags(self.dicom_tags, ds, self.dicom_tag_heirarchy)\n",
        "\n",
        "        # modify file metadata\n",
        "        ds.file_meta.MediaStorageSOPInstanceUID = instance_uid                              # Media Storage SOP Instance UID\n",
        "        ds.file_meta.ImplementationClassUID = str(pydicom.uid.PYDICOM_IMPLEMENTATION_UID)   # Implementation Class UID\n",
        "        ds.file_meta.ImplementationVersionName = str(pydicom.__version__)                   # Implementation Version Name\n",
        "\n",
        "        # delete tags\n",
        "        del ds[0x00080012]  # Instance Creation Date\n",
        "        del ds[0x00080013]  # Instance Creation Time\n",
        "        del ds[0x00080014]  # Instance Creator UID\n",
        "        # del ds[0x00100030]  # Patient's Birth Date\n",
        "\n",
        "        # modify tags\n",
        "        #-------------------------\n",
        "\n",
        "        ds['SOPClassUID'].value = '1.2.840.10008.5.1.4.1.1.88.22' # SOP Class UID = enhanced SR storage\n",
        "        ds[0x00080018].value = instance_uid  # SOPInstanceUID\n",
        "        ds[0x0008103e].value = str(self.metadata['name'].values[0])  # Series Description\n",
        "        ds[0x00080021].value = str(date)  # Series Date\n",
        "        ds[0x00080023].value = str(date)  # Content Date\n",
        "        ds[0x00080031].value = str(time)  # Series Time\n",
        "        ds[0x00080033].value = str(time)  # Content Time\n",
        "\n",
        "        ds[0x00181020].value = ''   # Software Versions\n",
        "\n",
        "        ds[0x0020000d].value = str(study_uid)   # Study Instance UID\n",
        "        ds[0x0020000e].value = str(series_uid)   # Series Instance UID\n",
        "        ds[0x00200011].value = str(1)           # Series Number\n",
        "\n",
        "        ds.Modality = 'SR'\n",
        "\n",
        "        # create dicom hierarchy\n",
        "        dicom_hier = self.dicom_hierarchy[study_uid]\n",
        "        series_sequence = []\n",
        "        for series in dicom_hier:\n",
        "          for key in series:\n",
        "            sops = series[key]\n",
        "            series_hier = Dataset()\n",
        "            sop_sequence = []\n",
        "            for sop in sops:\n",
        "              sop_data = Dataset()\n",
        "              if 'SOPClassUID' in self.dicom_tags:\n",
        "                sop_data.ReferencedSOPClassUID = self.dicom_tags['SOPClassUID']\n",
        "              sop_data.ReferencedSOPInstanceUID = sop\n",
        "              sop_sequence.append(sop_data)\n",
        "            series_hier.ReferencedSOPSequence = sop_sequence\n",
        "            series_hier.SeriesInstanceUID = key\n",
        "            series_sequence.append(series_hier)\n",
        "\n",
        "        ds[0x0040a375][0].ReferencedSeriesSequence = series_sequence\n",
        "        ds[0x0040a375][0].StudyInstanceUID = study_uid\n",
        "\n",
        "        # add tags\n",
        "        ds[0x00080005] = pydicom.dataelem.DataElement(0x00080005, 'CS', 'ISO_IR 192')       # Specific Character Set\n",
        "\n",
        "        # create content for each annotator\n",
        "        for i in range(len(annotators)):\n",
        "\n",
        "          instance_number = i+1\n",
        "          ds[0x00200013] = pydicom.dataelem.DataElement(0x00200013, 'IS', str(instance_number)) # Instance Number\n",
        "          ds[0x0040a730][0][0x0040a123].value = f'Annotator{instance_number}'\n",
        "          ds[0x0040a078][0][0x0040a123].value = f'Annotator{instance_number}'\n",
        "          anns = annotations[annotations.createdById == annotators[i]]\n",
        "\n",
        "          anns_map = {}\n",
        "          def annotator_iteration(row):\n",
        "            annotation = []\n",
        "            label_id = row['labelId']\n",
        "            parent_id = row['parentLabelId']\n",
        "            annotation.extend([parent_id, row['scope'], row['SOPInstanceUID'], row['SeriesInstanceUID']])\n",
        "            if 'SOPClassUID' in self.dicom_tags:\n",
        "                annotation.append(self.dicom_tags['SOPClassUID'])\n",
        "\n",
        "            if label_id not in anns_map:\n",
        "              anns_map[label_id] = []\n",
        "            anns_map[label_id].append(annotation)\n",
        "\n",
        "          anns.apply(annotator_iteration, axis=1)\n",
        "\n",
        "          # annotator_iteration has extraneous labels for those with child labels as it creates 2 separate entries for the child label and the parent label\n",
        "          for label_id in anns_map:\n",
        "            for annot in anns_map[label_id]:\n",
        "              if annot[0] != None:\n",
        "\n",
        "                if annot[0] not in anns_map: # Fixes edge case where a child label appears with no parent label for that annotator\n",
        "                  continue                   # Occurs when another annotator adds a child label to a different annotator's label\n",
        "\n",
        "                for j in range(len(anns_map[annot[0]])-1, -1, -1): #iterate backwards so can delete while iterating\n",
        "                  parent_annot = anns_map[annot[0]][j]\n",
        "                  if ((type(parent_annot[2]) == type(annot[2]) and type(annot[2] == float)) and (type(parent_annot[3]) == type(annot[3]) and type(annot[3] == float))) or ((parent_annot[2] == annot[2])  and (parent_annot[3] == annot[3])): # check if series and sop uid are same\n",
        "                    del anns_map[annot[0]][j]\n",
        "\n",
        "          content_sequence = []\n",
        "          code_number = 43770 #hello\n",
        "\n",
        "          # Create a list of labelIds ordered from exam to series to image\n",
        "          ordered_labels = []\n",
        "          j = 0\n",
        "          for label_id in anns_map:\n",
        "            if self.label_scope_map[label_id] == 'EXAM':\n",
        "              ordered_labels.insert(0, label_id)\n",
        "              j += 1\n",
        "            elif self.label_scope_map[label_id] == 'INSTANCE':\n",
        "              ordered_labels.append(label_id)\n",
        "            else:\n",
        "              ordered_labels.insert(j, label_id)\n",
        "\n",
        "          for label_id in ordered_labels:\n",
        "            for a in anns_map[label_id]:\n",
        "              # Add 'Referenced Segment' if label is in IMAGE scope\n",
        "              if a[1] == 'INSTANCE':\n",
        "                content = Dataset()\n",
        "                content.ValueType = 'IMAGE'\n",
        "                referenced_sequence_ds = Dataset()\n",
        "                if len(a) > 4:\n",
        "                  referenced_sequence_ds.ReferencedSOPClassUID = a[4]\n",
        "                referenced_sequence_ds.ReferencedSOPInstanceUID = a[2]\n",
        "                content.ReferencedSOPSequence = [referenced_sequence_ds]\n",
        "\n",
        "                code_sequence_ds = Dataset()\n",
        "                code_sequence_ds.CodeValue = str(code_number)\n",
        "                code_sequence_ds.CodingSchemeDesignator = '99MDAI'\n",
        "                code_sequence_ds.CodeMeaning = 'Referenced Image'\n",
        "                code_sequence = [code_sequence_ds]\n",
        "                content.ConceptNameCodeSequence = code_sequence\n",
        "                code_number += 1\n",
        "                content_sequence.append(content)\n",
        "\n",
        "              # Add parent label to text value\n",
        "              content = Dataset()\n",
        "              code_sequence_ds = Dataset()\n",
        "              if a[0] != None:\n",
        "                code_name = self.label_name_map[a[0]]\n",
        "              else:\n",
        "                code_name = self.label_name_map[label_id]\n",
        "              code_sequence_ds.CodeValue = str(hash(code_name))[1:6]\n",
        "              code_sequence_ds.CodingSchemeDesignator = '99MDAI'\n",
        "              code_sequence_ds.CodeMeaning = code_name\n",
        "              code_sequence = [code_sequence_ds]\n",
        "              content.ConceptNameCodeSequence = code_sequence\n",
        "\n",
        "              # Add child label text\n",
        "              text_value = ''\n",
        "              if a[0] != None:\n",
        "                text_value = ','.join(map(lambda labelId: self.label_name_map[labelId], [label_id]))\n",
        "                text_value += '\\n'\n",
        "                content.TextValue = text_value\n",
        "              # Add 'Series UID:'\n",
        "              if a[1] == 'SERIES':\n",
        "                text_value += f'Series UID: {series_uid}'\n",
        "                content.TextValue = text_value\n",
        "              if text_value != '':\n",
        "                content.ValueType = 'TEXT'\n",
        "              else:\n",
        "                content.ValueType = 'CONTAINER'\n",
        "              content_sequence.append(content)\n",
        "\n",
        "          ds[0x0040a730][1][0x0040a730][0].ContentSequence = content_sequence\n",
        "\n",
        "\n",
        "          ds.save_as(f'{os.getcwd()}/{out_dir}/DICOM_SR_{dataset_id}_{study_uid}_annotator_{instance_number}.dcm')\n",
        "\n",
        "  # Annotation dataframe has a separate row for a parent label. This function drops that row\n",
        "  def drop_dupes(self, row):\n",
        "    if row['parentLabelId'] != None:\n",
        "      if row['parentLabelId'] not in self.annots_df['labelId'].unique(): # Fixes edge case where a child label appears with no parent label for that annotator\n",
        "          return                                                    # Occurs when another annotator adds a child label to a different annotator's label\n",
        "      parents = self.annots_df[self.annots_df['labelId'] == row['parentLabelId']]\n",
        "      study_parents = parents[parents['StudyInstanceUID'] == row['StudyInstanceUID']]\n",
        "      series_parents = study_parents[study_parents['SeriesInstanceUID'] == row['SeriesInstanceUID']]\n",
        "      sop_parents = series_parents[series_parents['SOPInstanceUID'] == row['SOPInstanceUID']]\n",
        "\n",
        "      if len(sop_parents.index) > 0:\n",
        "        self.annots_df.drop(sop_parents.index[0], inplace=True)\n",
        "      elif len(series_parents.index) > 0:\n",
        "        self.annots_df.drop(series_parents.index[0], inplace=True)\n",
        "      elif len(study_parents.index) > 0:\n",
        "        self.annots_df.drop(study_parents.index[0], inplace=True)\n",
        "\n",
        "  # Gets imgs from annotations and creates segment sequence\n",
        "\n",
        "  def img_insert(self, row, ds):\n",
        "    data = self.load_mask_instance(row)\n",
        "    if not np.isscalar(data):\n",
        "      if self.prev_annot is not None and (self.prev_annot['labelId'] == row['labelId'] and self.prev_annot['labelGroupName'] == row['labelGroupName'] and self.prev_annot['instanceNumber'] == row['instanceNumber']):\n",
        "        mask2 = self.load_mask_instance(row)\n",
        "        self.imgs[-1] = np.ma.mask_or(self.imgs[-1], mask2)\n",
        "      else:\n",
        "        self.imgs.append(self.load_mask_instance(row))\n",
        "        self.included_sops.append((len(self.seen_labels)+1, row['SOPInstanceUID']))\n",
        "        self.unique_sops.add(row['SOPInstanceUID'])\n",
        "        self.name_number_map[len(self.seen_labels)+1] = row['labelName']\n",
        "      self.prev_annot = row\n",
        "\n",
        "      if row['labelId'] not in self.seen_labels:\n",
        "        if row['parentLabelId'] == None:\n",
        "          parent_label_name = self.label_name_map[row['labelId']]\n",
        "        else:\n",
        "          parent_label_name = self.label_name_map[row['parentLabelId']]\n",
        "        child_label_name = self.label_name_map[row['labelId']]\n",
        "\n",
        "        segment_sequence = ds.SegmentSequence\n",
        "\n",
        "        segment1 = Dataset()\n",
        "        segment_sequence.append(segment1)\n",
        "\n",
        "        # Segmented Property Category Code Sequence\n",
        "        segmented_property_category_code_sequence = Sequence()\n",
        "        segment1.SegmentedPropertyCategoryCodeSequence = segmented_property_category_code_sequence\n",
        "\n",
        "        # Segmented Property Category Code Sequence: Segmented Property Category Code 1\n",
        "        segmented_property_category_code1 = Dataset()\n",
        "        segmented_property_category_code_sequence.append(segmented_property_category_code1)\n",
        "        segmented_property_category_code1.CodeValue = str(hash(parent_label_name))[1:6]\n",
        "        segmented_property_category_code1.CodingSchemeDesignator = '99MDAI'\n",
        "        segmented_property_category_code1.CodeMeaning = f'{parent_label_name} from Label Group {row[\"labelGroupName\"]}'\n",
        "\n",
        "        segment1.SegmentNumber = len(self.seen_labels)+1 # (number of labels)\n",
        "        segment1.SegmentLabel = child_label_name\n",
        "        segment1.SegmentAlgorithmType = 'MANUAL' # Maybe change based on how it was created\n",
        "\n",
        "        # Segmented Property Type Code Sequence\n",
        "        segmented_property_type_code_sequence = Sequence()\n",
        "        segment1.SegmentedPropertyTypeCodeSequence = segmented_property_type_code_sequence\n",
        "\n",
        "        # Segmented Property Type Code Sequence: Segmented Property Type Code 1\n",
        "        segmented_property_type_code1 = Dataset()\n",
        "        segmented_property_type_code_sequence.append(segmented_property_type_code1)\n",
        "        segmented_property_type_code1.CodeValue = str(hash(child_label_name))[1:6]\n",
        "        segmented_property_type_code1.CodingSchemeDesignator = '99MDAI'\n",
        "        segmented_property_type_code1.CodeMeaning = child_label_name\n",
        "\n",
        "        self.seen_labels.add(row['labelId'])\n",
        "\n",
        "  def load_mask_instance(self, row):\n",
        "      \"\"\"Load instance masks for the given annotation row. Masks can be different types,\n",
        "      mask is a binary true/false map of the same size as the image.\n",
        "      \"\"\"\n",
        "\n",
        "      if row.data == None:\n",
        "        return 404 # no data found\n",
        "\n",
        "      mask = np.zeros((int(row.height), int(row.width)), dtype=np.uint8)\n",
        "\n",
        "      annotation_mode = row.annotationMode\n",
        "\n",
        "      if annotation_mode == 'bbox':\n",
        "          # Bounding Box\n",
        "          x = int(row.data['x'])\n",
        "          y = int(row.data['y'])\n",
        "          w = int(row.data[\"width\"])\n",
        "          h = int(row.data[\"height\"])\n",
        "          mask_instance = mask[:,:].copy()\n",
        "          cv2.rectangle(mask_instance, (x, y), (x + w, y + h), 255, -1)\n",
        "          mask[:,:] = mask_instance\n",
        "\n",
        "      # FreeForm or Polygon\n",
        "      elif annotation_mode == \"freeform\" or annotation_mode == \"polygon\":\n",
        "          vertices = np.array(row.data[\"vertices\"])\n",
        "          vertices = vertices.reshape((-1, 2))\n",
        "          mask_instance = mask[:,:].copy()\n",
        "          cv2.fillPoly(mask_instance, np.int32([vertices]), (255, 255, 255))\n",
        "          mask[:,:] = mask_instance\n",
        "\n",
        "      # Line\n",
        "      elif annotation_mode == \"line\":\n",
        "          vertices = np.array(row.data[\"vertices\"])\n",
        "          vertices = vertices.reshape((-1, 2))\n",
        "          mask_instance = mask[:,:].copy()\n",
        "          cv2.polylines(mask_instance, np.int32([vertices]), False, (255, 255, 255), 12)\n",
        "          mask[:,:] = mask_instance\n",
        "\n",
        "      elif annotation_mode == \"location\":\n",
        "          # Bounding Box\n",
        "          x = int(row.data[\"x\"])\n",
        "          y = int(row.data[\"y\"])\n",
        "          mask_instance = mask[:,:].copy()\n",
        "          cv2.circle(mask_instance, (x, y), 7, (255, 255, 255), -1)\n",
        "          mask[:,:] = mask_instance\n",
        "\n",
        "      elif annotation_mode == 'ellipse':\n",
        "        cx = int(row.data[\"cx\"])\n",
        "        cy = int(row.data[\"cy\"])\n",
        "        rx = int(row.data[\"rx\"])\n",
        "        ry = int(row.data[\"ry\"])\n",
        "        mask_instance = mask[:,:].copy()\n",
        "        cv2.ellipse(mask_instance, (cx,cy), (rx,ry), 0, 0, 360, (255,255,255), 12)\n",
        "        mask[:,:] = mask_instance\n",
        "\n",
        "      elif annotation_mode == \"mask\":\n",
        "          mask_instance = mask[:, :].copy()\n",
        "          if row.data[\"foreground\"]:\n",
        "              for i in row.data[\"foreground\"]:\n",
        "                  mask_instance = cv2.fillPoly(mask_instance, [np.array(i, dtype=np.int32)], (255, 255, 255))\n",
        "          if row.data[\"background\"]:\n",
        "              for i in row.data[\"background\"]:\n",
        "                  mask_instance = cv2.fillPoly(mask_instance, [np.array(i, dtype=np.int32)], (0,0,0))\n",
        "          mask[:, :] = mask_instance\n",
        "\n",
        "      return mask.astype(bool)\n",
        "\n",
        "  def create_seg_exports(self):\n",
        "    \"\"\"\n",
        "    Creates a template SEG File and adds in necessary SEG information\n",
        "    Instead of working from a template, this function creates a segmentation file from scratch using pydicom\n",
        "    \"\"\"\n",
        "    try:\n",
        "      if self.output_dir == None:\n",
        "        out_dir = 'SEG_Output'\n",
        "        os.mkdir('SEG_Output')\n",
        "      else:\n",
        "        out_dir = self.output_dir\n",
        "        os.mkdir(self.output_dir)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    self.annots_df.apply(self.drop_dupes, axis=1)\n",
        "\n",
        "    for dataset_id in self.annots_df['datasetId'].unique():\n",
        "      self.dataset_annots = self.annots_df[self.annots_df.datasetId == dataset_id]\n",
        "      for study_uid in self.studies:\n",
        "        dicom_hier = self.dicom_hierarchy[study_uid]\n",
        "        series_sequence = []\n",
        "        for series_dict in dicom_hier:\n",
        "          for series_uid in series_dict:\n",
        "            sops = series_dict[series_uid]\n",
        "\n",
        "            annotations = self.dataset_annots[self.dataset_annots.SeriesInstanceUID == series_uid]\n",
        "            annotations = annotations[annotations['scope'] == \"INSTANCE\"]\n",
        "            if annotations.empty:\n",
        "              continue\n",
        "\n",
        "            self.dicom_tags = self.tags_df[self.tags_df.SeriesInstanceUID == series_uid].dicomTags.values[0]\n",
        "            annotators = annotations.createdById.unique()\n",
        "            instance_uid = pydicom.uid.generate_uid(prefix=None)\n",
        "            date = datetime.now().strftime('%Y%m%d')\n",
        "            time = datetime.now().strftime('%H%M%S')\n",
        "\n",
        "            sop_instance_num_map = {}\n",
        "            for sop in sops:\n",
        "\n",
        "              sop_dicom_tags = self.tags_df[self.tags_df.SOPInstanceUID == sop].dicomTags.values[0]\n",
        "              if 'InstanceNumber' in sop_dicom_tags:\n",
        "                sop_instance_num_map[sop] = sop_dicom_tags['InstanceNumber']\n",
        "              else:\n",
        "                sop_instance_num_map[sop] = '1'\n",
        "\n",
        "            def create_instance_number(row):\n",
        "              return sop_instance_num_map[row['SOPInstanceUID']]\n",
        "\n",
        "            b = annotations\n",
        "            annotations['instanceNumber'] = annotations.apply(create_instance_number, axis=1)\n",
        "            annotations = annotations.sort_values(['labelGroupName', 'labelId', 'instanceNumber'], ignore_index=True) # sort by label group then annotation then appearance in series\n",
        "\n",
        "            # File meta info data elements\n",
        "            file_meta = FileMetaDataset()\n",
        "            file_meta.FileMetaInformationVersion = b'\\x00\\x01'\n",
        "            file_meta.TransferSyntaxUID = '1.2.840.10008.1.2.1'\n",
        "            file_meta.MediaStorageSOPInstanceUID = instance_uid   # Create Instance UID      # Media Storage SOP Instance UID\n",
        "            file_meta.ImplementationClassUID = str(pydicom.uid.PYDICOM_IMPLEMENTATION_UID)   # Implementation Class UID\n",
        "            file_meta.ImplementationVersionName = str(pydicom.__version__)                   # Implementation Version Name\n",
        "            file_meta.SourceApplicationEntityTitle = 'POSDA'\n",
        "\n",
        "            # Main data elements\n",
        "            ds = Dataset()\n",
        "\n",
        "            ds = self.place_tags(self.dicom_tags, ds, self.dicom_tag_heirarchy, True)\n",
        "\n",
        "            ds.SpecificCharacterSet = 'ISO_IR 192'\n",
        "            ds.SOPClassUID = '1.2.840.10008.5.1.4.1.1.66.4'\n",
        "            ds.SOPInstanceUID = instance_uid\n",
        "            ds.SeriesDate = str(date)  # Series Date\n",
        "            ds.ContentDate = str(date)  # Content Date\n",
        "            ds.SeriesTime = str(time) # Series Time\n",
        "            ds.ContentTime = str(time) # Series Time\n",
        "            ds.Manufacturer = 'MDAI'\n",
        "            ds.Modality = 'SEG'\n",
        "\n",
        "            # Referenced Series Sequence\n",
        "            refd_series_sequence = Sequence()\n",
        "            ds.ReferencedSeriesSequence = refd_series_sequence\n",
        "\n",
        "            # Referenced Series Sequence: Referenced Series 1\n",
        "            refd_series1 = Dataset()\n",
        "            refd_series_sequence.append(refd_series1)\n",
        "\n",
        "            # Referenced Series Sequence: Referenced Series 1\n",
        "            refd_series1 = Dataset()\n",
        "            refd_series_sequence.append(refd_series1)\n",
        "            refd_series1.SeriesInstanceUID = series_uid\n",
        "\n",
        "            # Referenced Instance Sequence\n",
        "            refd_instance_sequence = Sequence()\n",
        "            refd_series1.ReferencedInstanceSequence = refd_instance_sequence\n",
        "\n",
        "            ds.SegmentationType = 'BINARY'\n",
        "\n",
        "            for annotator_id in annotators:\n",
        "              annotator_annots = annotations[annotations.createdById == annotator_id]\n",
        "\n",
        "              if self.combine:\n",
        "                label_group_sets = [annotator_annots.labelGroupName.unique()]\n",
        "              else:\n",
        "                label_group_sets = [[group] for group in annotator_annots.labelGroupName.unique()]\n",
        "\n",
        "              ds.SamplesPerPixel = 1\n",
        "              ds.PhotometricInterpretation = 'MONOCHROME2'\n",
        "              ds.BitsAllocated = 1\n",
        "              ds.BitsStored = 1\n",
        "              ds.HighBit = 0\n",
        "              ds.PixelRepresentation = 0\n",
        "              ds.LossyImageCompression = '00'\n",
        "\n",
        "              for label_group_set in label_group_sets:\n",
        "                label_group_annots = annotator_annots[annotator_annots.labelGroupName.isin(label_group_set)]\n",
        "\n",
        "                # Segment Sequence\n",
        "                segment_sequence = Sequence()\n",
        "                ds.SegmentSequence = segment_sequence\n",
        "\n",
        "                self.imgs = []\n",
        "                self.seen_labels = set()\n",
        "                self.name_number_map = {}\n",
        "                self.included_sops = []\n",
        "                self.unique_sops = set()\n",
        "                self.label_groups = list(annotations.labelGroupName.unique())\n",
        "                self.prev_annot = None\n",
        "                label_group_annots.apply(self.img_insert, args=(ds,), axis=1)\n",
        "\n",
        "                ds.NumberOfFrames = len(self.imgs) # create during last parts of SEG file (should equal length of annot_df)\n",
        "                ds.PixelData = pack_bits(np.array(self.imgs))\n",
        "\n",
        "                for sop in self.unique_sops:\n",
        "                  sop_dicom_tags = self.tags_df[self.tags_df.SOPInstanceUID == sop].dicomTags.values[0]\n",
        "                  refd_instance1 = Dataset()\n",
        "                  refd_instance_sequence.append(refd_instance1)\n",
        "                  if 'SOPClassUID' in sop_dicom_tags:\n",
        "                    refd_instance1.ReferencedSOPClassUID = sop_dicom_tags['SOPClassUID']\n",
        "                  refd_instance1.ReferencedSOPInstanceUID = sop_dicom_tags['SOPInstanceUID']\n",
        "\n",
        "                # Leaving it out for now but if nothing works then maybe try to add it back in blank and then with dummy values\n",
        "                # Edit: added it back in but still unnecessary.\n",
        "                # -----------------------------------------------------------------------\n",
        "                # Dimension Index Sequence\n",
        "                dimension_index_sequence = Sequence()\n",
        "                ds.DimensionIndexSequence = dimension_index_sequence\n",
        "                # -----------------------------------------------------------------------\n",
        "\n",
        "                ds.ContentLabel = 'MDAI_SEG'\n",
        "                ds.ContentCreatorName = f'annotator {annotator_id}'\n",
        "\n",
        "                # Leaving it out for now but if nothing works then maybe try to add it back in blank and then with dummy values\n",
        "                # Edit: added it back in but still unnecessary.\n",
        "                # -----------------------------------------------------------------------\n",
        "                # Shared Functional Groups Sequence\n",
        "                shared_functional_groups_sequence = Sequence()\n",
        "                ds.SharedFunctionalGroupsSequence = shared_functional_groups_sequence\n",
        "                # -----------------------------------------------------------------------\n",
        "\n",
        "                # Per-frame Functional Groups Sequence\n",
        "                per_frame_functional_groups_sequence = Sequence()\n",
        "                ds.PerFrameFunctionalGroupsSequence = per_frame_functional_groups_sequence\n",
        "\n",
        "                # Per-frame Functional Groups Sequence\n",
        "                per_frame_functional_groups_sequence = Sequence()\n",
        "                ds.PerFrameFunctionalGroupsSequence = per_frame_functional_groups_sequence\n",
        "\n",
        "                # Per-frame Functional Groups Sequence\n",
        "                per_frame_functional_groups_sequence = []\n",
        "\n",
        "                # Loop through each frame with an annotation and create unique Per Frame Functional Group Sequence\n",
        "                # ---------------------------------------------------------------------------\n",
        "                for segment_number, sop in self.included_sops:\n",
        "\n",
        "                  label_names = ', '.join(label_group_annots['labelName'].unique())\n",
        "                  ds.SeriesDescription = f'Segmentation of {label_names} by annotator {annotator_id}'\n",
        "\n",
        "                  sop_dicom_tags = self.tags_df[self.tags_df.SOPInstanceUID == sop].dicomTags.values[0]\n",
        "\n",
        "                  # Per-frame Functional Groups Sequence: Per-frame Functional Groups 1\n",
        "                  per_frame_functional_groups1 = Dataset()\n",
        "                  per_frame_functional_groups_sequence.append(per_frame_functional_groups1)\n",
        "\n",
        "                  # Derivation Image Sequence\n",
        "                  derivation_image_sequence = Sequence()\n",
        "                  per_frame_functional_groups1.DerivationImageSequence = derivation_image_sequence\n",
        "\n",
        "                  # Derivation Image Sequence: Derivation Image 1\n",
        "                  derivation_image1 = Dataset()\n",
        "                  derivation_image_sequence.append(derivation_image1)\n",
        "\n",
        "                  # Source Image Sequence\n",
        "                  source_image_sequence = Sequence()\n",
        "                  derivation_image1.SourceImageSequence = source_image_sequence\n",
        "\n",
        "                  # Source Image Sequence: Source Image 1\n",
        "                  source_image1 = Dataset()\n",
        "                  source_image_sequence.append(source_image1)\n",
        "                  if 'SOPClassUID' in self.dicom_tags:\n",
        "                    source_image1.ReferencedSOPClassUID = self.dicom_tags['SOPClassUID']\n",
        "                  source_image1.ReferencedSOPInstanceUID = self.dicom_tags['SOPInstanceUID']\n",
        "\n",
        "                  # Purpose of Reference Code Sequence\n",
        "                  purpose_of_ref_code_sequence = Sequence()\n",
        "                  source_image1.PurposeOfReferenceCodeSequence = purpose_of_ref_code_sequence\n",
        "\n",
        "                  # Purpose of Reference Code Sequence: Purpose of Reference Code 1\n",
        "                  purpose_of_ref_code1 = Dataset()\n",
        "                  purpose_of_ref_code_sequence.append(purpose_of_ref_code1)\n",
        "                  purpose_of_ref_code1.CodeValue = '121322'\n",
        "                  purpose_of_ref_code1.CodingSchemeDesignator = 'DCM'\n",
        "                  purpose_of_ref_code1.CodeMeaning = 'Source image for image processing operation'\n",
        "\n",
        "                  # Derivation Code Sequence\n",
        "                  derivation_code_sequence = Sequence()\n",
        "                  derivation_image1.DerivationCodeSequence = derivation_code_sequence\n",
        "\n",
        "                  # Derivation Code Sequence: Derivation Code 1\n",
        "                  derivation_code1 = Dataset()\n",
        "                  derivation_code_sequence.append(derivation_code1)\n",
        "                  derivation_code1.CodeValue = '113076'\n",
        "                  derivation_code1.CodingSchemeDesignator = 'DCM'\n",
        "                  derivation_code1.CodeMeaning = 'Segmentation'\n",
        "\n",
        "                  # Segment Identification Sequence\n",
        "                  segment_id_seq = Dataset()\n",
        "                  per_frame_functional_groups1.SegmentIdentificationSequence = [segment_id_seq]\n",
        "\n",
        "                  # Segment Number\n",
        "                  segment_id_seq.ReferencedSegmentNumber = segment_number\n",
        "\n",
        "                  per_frame_functional_groups1 = self.place_tags(sop_dicom_tags, per_frame_functional_groups1, self.dicom_tag_heirarchy['PerFrameFunctionalGroupsSequence'], False)\n",
        "                # -------------------------------------------------------------------------\n",
        "\n",
        "                ds.PerFrameFunctionalGroupsSequence = per_frame_functional_groups_sequence\n",
        "\n",
        "                ds.file_meta = file_meta\n",
        "                ds.is_implicit_VR = False\n",
        "                ds.is_little_endian = True\n",
        "\n",
        "                if self.included_sops:\n",
        "                  if self.combine:\n",
        "                    ds.save_as(f'{os.getcwd()}/{out_dir}/DICOM_SEG_{dataset_id}_{series_uid}_annotator_{annotator_id}.dcm', False)\n",
        "                  else:\n",
        "                    ds.save_as(f'{os.getcwd()}/{out_dir}/DICOM_SEG_{dataset_id}_label_group_{label_group_set[0]}_series_{series_uid}_annotator_{annotator_id}.dcm', False)                                                                                            #spike was here\n"
      ]
    }
  ]
}
